```{r}
## generalizability 
eig_gen_stats <- readRDS(here("cached_data/writing_cache/clean_eig_gen_stats.Rds")) %>% mutate(across(is.numeric, round, 2))
eig_qual_order <- readRDS(here("cached_data/writing_cache/clean_eig_gen_qual_order.Rds"))

# robustness
kfold_eig_params <- readRDS(here("cached_data/eig_aligned_fit_res.Rds"))
best_fit_id <- (kfold_eig_params %>% arrange(-mean_rsquared))$param_id[[1]]
# looking up params manually from other file
all_params <- read_csv(here("data/model_sim_data/sim_info/eig_selfpaced.csv"))
eig_stats <- readRDS(here("cached_data/writing_cache/clean_eig_stats.Rds"))%>% mutate(across(is.numeric, round, 2))
all_eig_params <- readRDS(here("cached_data/eig_nofold_fit.Rds"))
n_params <- nrow(all_eig_params)
eig_rsquared_mean <- round(mean(all_eig_params$rsquared), 2)
eig_rsquared_sd <- round(sd(all_eig_params$rsquared), 2)
eig_rmse_mean <- round(mean(all_eig_params$rmse), 2)
eig_rmse_sd <- round(sd(all_eig_params$rmse, na.rm = TRUE), 2)
eig_qual_order <- readRDS(here("cached_data/writing_cache/clean_eig_qual_order.Rds"))

# alternative models 
nonoise_stats <- readRDS(here("cached_data/writing_cache/clean_nonoise_stats.Rds"))%>% mutate(across(is.numeric, round, 2))
nolearning_stats <- readRDS(here("cached_data/writing_cache/clean_nolearning_stats.Rds"))%>% mutate(across(is.numeric, round, 2))
randemb_stats <- readRDS(here("cached_data/writing_cache/clean_randemb_stats.Rds"))%>% mutate(across(is.numeric, round, 2))

# plotting 
all_data <- readRDS(here("cached_data/writing_cache/plotting_df.Rds"))
```


```{r lol, fig.env = "figure*", fig.pos = "h!", fig.width=6.6, fig.height=4, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Human behaviors and model performance of RANCH and alternative models. For the human panel, X-axis shows the trial number, y-axis shows the looking time at each trial to the test stimuli in milliseconds. The line shows the fit from the preregistered linear mixed effect model. For the remaining panels, Y-axis represents the samples model made on each trial, scaled to the behavioral data. Different colors represents different trial types."}

trial_color <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442")
all_data %>% 
  ggplot() + 
  geom_rect(data = all_data, aes(fill = hue),
            xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, alpha = 0.1)+ 
  #scale_y_log10() + 
  geom_pointrange(
    aes(x = trial_number, y = scaled_samples, ymin = scaled_lb, ymax = scaled_ub, color  = trial_type),
    position = position_dodge(width = .2)) + 
  geom_line(
     aes(x = trial_number, y = scaled_samples, color = trial_type, alpha = is_human), 
     position = position_dodge(width = .2)
  )+
  scale_alpha_discrete(range = c(1, 0), guide = "none") + 
  scale_color_manual(values=trial_color) +  
  theme_few()+ 
  guides(color=guide_legend(title="Trial Type"))+
  ylab("") + 
  xlab("") + 
  scale_x_continuous(breaks = seq(1, 6)) + 
  theme(legend.position = "top", 
        strip.text.x = element_text(size = 8)) + 
  facet_wrap(~type) + 
  geom_line(data = subset(all_data, is_human == TRUE), aes(x = trial_number, y = fit, color = trial_type)) + 
  scale_fill_identity() +
  geom_rect(data = subset(all_data, is_human == TRUE),xmin = -Inf,xmax = Inf,ymin = -Inf,ymax = Inf,alpha=0.003, fill = "lightgray") + 
  scale_fill_identity()
```

## Parameter generalizability 

We conducted an interactive grid search across free parameters to find the best parameters that fit to the training dataset. The best fitting parameter ($\mu_{p}$ = 0,$\nu_{p}$ = 1, $\alpha_{p}$ = 1, $\beta_{p}$ = 1, $\epsilon$ = 0.0001) predicted the habituation and dishabituation in the training data ($r^2$ = 0.95 [0.90, 0.98]). Using these previously obtained parameters, we now test RANCH’s performance on the current experiment with different stimuli and design. We found that the parameters generalized to the current context well ($r^2$: `r paste(eig_gen_stats$rsquared, eig_gen_stats$r_conf_print)`, *RMSE*:  `r paste(eig_gen_stats$rmse, eig_gen_stats$rmse_conf_print)`). Moreover, RANCH also showed the qualitative ordering of the graded dishabituation similar to the behavioral data: animacy > identity > number > pose.  

## Parameter robustness 

To evaluate RANCH’s robustness to different parameters, we then conducted a grid search over the parameters. We selected the best fitting parameters ($\mu_{p}$ = 0,$\nu_{p}$ = 2, $\alpha_{p}$ = 10, $\beta_{p}$ = 1, $\epsilon$ = 0.0001) using a 10-fold cross-validation on the behavioral dataset.  When fit to the full dataset, the best fitting parameter from this search was comparable with the parameters generalized from the training dataset ($r^2$: `r paste(eig_stats$rsquared, eig_stats$r_conf_print)`, *RMSE*:  `r paste(eig_stats$rmse, eig_stats$rmse_conf_print)`).  Moreover, the performance across the `r n_params` parameter settings are relatively stable, yielding a moderate range of R-squared (*M* = `r eig_rsquared_mean`; *SD* = `r eig_rsquared_sd`) and RMSE (*M* = `r eig_rmse_mean`; *SD* = `r eig_rmse_sd`). Finally, the qualitative ordering of the dishabituation magnitude is also preserved when averaged across all parameter settings. 

## Comparison with alternative models

Finally, to examine whether the assumptions in our models are critical to the success of our models, we ran three alternative models: Random Embedding model, No Noise model, and No Learning Model. We ran a parameter search for each of the model, and all of the models showed worse performance compared to RANCH (Random Embedding: $r^2$: `r paste(randemb_stats$rsquared, randemb_stats$r_conf_print)`, *RMSE*:  `r paste(randemb_stats$rmse, randemb_stats$rmse_conf_print)`; No Noise: $r^2$: `r paste(nonoise_stats$rsquared, nonoise_stats$r_conf_print)`, *RMSE*: `r paste(nonoise_stats$rmse, nonoise_stats$rmse_conf_print)`; No Learning: `r paste(nolearning_stats$rsquared, nolearning_stats$r_conf_print)`, *RMSE*: `r paste(nolearning_stats$rmse, nolearning_stats$rmse_conf_print)`). 







