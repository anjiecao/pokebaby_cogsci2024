
We next wanted to ask whether looking time in our task can be seen as rational information acquisition, using a “rational analysis” approach previously described for a variety of aspects of human behavior [@oaksford1994rational; @dubey2020reconciling].  Our goal was to develop a model which formalizes the entire process underlying looking time: from perception of a stimulus to deciding how long to look at it. To do so, our model has three separate components describing 1) the perceptual embeddings RANCH learns from 2) how RANCH learns a concept over this perceptual space and 3) how RANCH makes decisions about how long to sample from a stimulus based on its expected information gain. Here, we describe these three components in turn.


### Perceptual representation 

To allow RANCH to operate on raw images, we used the perceptually-aligned embeddings obtained from a model presented recently by @lee2022rapid. We use these projections into a perceptually-aligned embedding space as a principled low-dimensional representation of stimuli, over which our learning model can form perceptual concepts. We used the first three principal components of the embedding space. 57.9% of the variance was captured by these first three PCs. A visualization of experimental stimuli in the embedding space can be seen in Figure 2A.

### Learning model 

RANCH's goal is to learn a concept in the perceptual embedding space described above, through noisy perceptual samples from a stimulus. The concept is parameterized by a 3D Gaussian $(\mu,\sigma)$, which represents beliefs about the location and variance of the concept in the embedding space. This concept $(\mu,\sigma)$ generates exemplars $(y)$: exemplars of the concept. RANCH observes repeated noisy samples $(\bar{z})$ from each exemplar. For any sample $(z)$ from an exemplar $(y)$, the model expects the observation to get corrupted by zero-mean gaussian noise with standard deviation  $(\epsilon)$. A plate diagram is shown in Figure 1B. We used a normal-inverse-gamma prior on the concept, the conjugate prior for a normal with unknown mean and variance, on the concept parameterized as $\mu_{p}$,$\nu_{p}$,$\alpha_{p}$, $\beta_{p}$. Still, applying perceptual noise to $y$ breaks the conjugate relation, so we computed approximate posteriors using grid approximation over $(\mu,\sigma)$ and $(\epsilon)$. This computationally expensive approximation was accomplished through a pytorch implementation and distributed GPU computation. 


### Decision model 

To decide whether to take an additional sample from the same stimulus, RANCH computes expected information gain (EIG) of the next sample. EIG is computed as the product of the posterior predictive probability of the next sample and the information gained conditioned on that next sample, by iterating through a grid of possible subsequent samples. RANCH then makes a softmax choice (with temperature = 1) between taking another sample and looking away. We assumed that participants expect a constant information gain from looking away (the “world EIG”). Therefore, as EIG from the stimulus drops below world EIG, it becomes increasingly likely that RANCH will look away.


### Simulating the experiment 

To model the behavioral experiment, we first extracted the first three principal components of the embeddings of all the stimuli used in the experiment. We assembled the stimuli into sequences following the stimuli sequence participants saw in each block. For the block with deviating stimuli, we sampled deviant stimuli from corresponding violation categories. We sampled 23 stimuli pairs for each combination of violation type and deviant position. Since the model makes stochastic sampling decisions, we conducted 400 runs for each stimuli sequence for each parameter setting. 


### Alternative models 

To test the importance of each of RANCH’s components for its performance, we defined three lesioned models, in which one key feature of the model was removed. First, to test the importance of the perceptual embeddings, we ran a version of RANCH in which the mappings from stimulus labels to embeddings were permuted, such that which embedding was associated with which violation type was randomized (“Random embeddings”). Second, we ran a version in which RANCH assumes that each perceptual sample in the learning process is noiseless, rather than corrupted by $\epsilon$ (“No noise”).Third, we ran a version in which RANCH made decisions randomly rather than based on the learning model (“No learning”).


### Training Data 

We used the behavioral dataset reported in @cao2023habituation as the training data. In this prior experiment, 449 adults participated in a self-paced viewing of sequences of simple stimuli. The procedure was similar to the present experiment with two key differences: First, stimuli used in this previous experiment were animated monsters. Second, unlike the current study, the previous experiment only contained dishabituation stimuli that varied in the identity of the monster (comparable to the “identity violation” stimuli in the current experiment) There was no manipulation on the dissimilarity between the repeating stimulus and the deviant stimulus in a block. 

