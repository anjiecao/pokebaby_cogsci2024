In this paper, we report on a novel experiment in which participants are familiarized to sequences of animations, and we measure habituation and their dishabituation to different types of violations of familiar stimuli. We find that adults’ dishabituation is graded by the type of violation they see, and that the magnitude of dishabituation is predicted by a rational model which takes noisy samples from perceptual embeddings of the same stimuli that participants saw. Our model, RANCH, through its use of perceptual embeddings, operates directly on raw images and therefore can generate predictions for previously unseen stimuli or even tasks. Making use of this property, we tested RANCH’s performance on our graded dishabituation task using parameters fit to behavior on a completely different self-paced looking time task.

Lesioning RANCH by removing key components caused its fit to the data to drop substantially relative to the full model and eliminated any sense of qualitative correspondence to the human data. This result suggests that the aspects that we lesioned - a psychologically-plausible embedding space, noisy perception, connecting sampling to concept learning - are all essential for explaining behavior in our task.

There are several directions in which RANCH could be extended in future work. First, in the current paper, we implemented a specific version of RANCH, with a specific form for each of its components: the perceptual representation, the learning model, and the linking hypothesis between learning and attentional sampling. However, RANCH’s modular and interpretable structure allows researchers to adjust its components according to the population or task for which predictions are being generated. For example, the perceptual embedding space used in this paper was aligned to adult behavior [@lee2022rapid], but infants likely represent visual objects differently from adults. Using perceptual representations based on visual input experienced by infants may provide a better fit to infant data [@zhuang2021unsupervised; @orhan2023can]. Similarly, task settings in which there was hierarchical structure to the stimuli sequences would call for more complicated learning models. The linking hypothesis can also vary: In previous work we have also explored the effect of replacing the rational, but computationally expensive, EIG with easier-to-compute information-theoretic quantities such as surprisal or KL-divergence [@cao2023habituation; @raz2023modeling]. While previous work has found that these linking hypotheses are interchangeable in the current context, it is possible that they would dissociate under different task settings or different assumptions about the perceptual representations.

Second, while inspired by infant looking time research, our current work only has adult participants. Beyond encoding stimuli differently from infants, adults may conceptualize our task differently from infants, and experience different task demands. In particular, infants are quite sensitive to changes in the number of objects that are displayed [@wynn1992addition; @feigenson2003tracking], but in the current study, adults dishabituated to number violations as little as to pose violations, the subtlest violation in our task. This suggests that adults may have not engaged their number cognition in the way we would expect infants to in this task. Furthermore, given the interpretability of the model parameters we fit to behavior, conducting the same experiment with infants may lead to interpretable developmental differences in the model parameters, such as priors on perceptual noise and prior uncertainty about the mean and standard deviation of perceptual concepts.

Overall, our work presents a rational model, RANCH, which describes how humans decide how long to look at stimuli. Using a psychologically motivated visual encoding model allows RANCH to operate on raw images, and generate predictions for previously unseen stimuli or tasks. We think that the generality and interpretability of our model framework constitutes a significant step towards predictive modeling of adult, and eventually infant, looking time, thereby putting the field on firmer ground.

