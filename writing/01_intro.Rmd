
From birth, humans learn actively. Even before they can move on their own, infants can select information by deciding what to look at and when to stop looking [@haith1980rules; @raz2020learning]. Developmental psychologists have long leveraged this attentional decision-making to make inferences about the perceptual and cognitive abilities of infants by measuring how long infants look at certain stimuli [@aslin2007s; @baillargeon1985object; @fantz1963pattern]. 

Two key phenomena are particularly critical for these inferences: habituation and dishabituation. Habituation refers to the decrease in looking time upon seeing the same or similar stimuli repeatedly; dishabituation refers to the increase in looking time following the presentation of a novel stimulus after habituation. In order to dishabituate, the infant must distinguish between the original stimulus and the novel one.  While habituation and dishabituation have been robustly documented, the underlying mechanisms of these looking time changes remain poorly understood. In this paper, we address this gap by presenting a rational model that provides principled predictions about the magnitude of dishabituation. Critically, this model can be applied generally to make predictions about looking time for arbitrary stimuli by using embeddings derived from a convolutional neural network.

The dominant model of infant looking time proposes that habituation and dishabituation are driven by the amount of information to be encoded in the stimulus [@hunter1988multifactor]. Observers look longer at a stimulus if the stimulus has a lot of unencoded information, and as exposure to the stimulus accumulates, less information is left unencoded, leading to shorter looking time. While this theory has been highly influential, the lack of formal details about what is meant by “encoding” opens the door for post-hoc interpretation of looking time measurements. A stimulus could be argued to be novel because it has distinct perceptual features, but it could also be familiar because of its conceptual characteristics (or perhaps both at the same time). In part as a result of this interpretive ambiguity, concerns have been raised repeatedly about whether looking time measurements should be the foundation for central claims in developmental psychology [@blumberg2023protracted; @haith1998put; @paulus2022should]. 

Computational models provide an important tool for formalizing the details of the habituation and dishabituation process. One set of models describes infants’ looking behaviors with information-theoretic measures derived from ideal observer models [@kidd2012goldilocks; @poli2020infants; @poli2023eight]. For example, @poli2023eight developed a model that learned probability distributions from sequences of events. They then calculated the Kullback–Leibler (KL) divergence between the model’s parameters before and after each event in a sequence, capturing how much the model learned from each observation.  This measure was shown to predict infants’ looking behavior, with higher KL associated with lower probabilities of infants looking away. 

While this type of model provides a quantitative account of the habituation process, it does not model the infant’s information sampling process directly. Instead, it describes trial-level correlations between model-derived, information-theoretic measures and infant looking times. Essentially, this type of model fails to elucidate the causal relationship between information theoretic measurements and infant’s samling decision. . Furthermore, it presupposes an abstracted representation of the stimuli as a sequence of schematic events (e.g., 1, 2, 1, 1, 3, etc.) rather than instantiating a hypothesis about how visual encoding occurs during attentional decision-making. This feature limits the ability of these models to make principled predictions about looking time for new stimuli.

To address these issues, Rational Action, Noisy Choice for Habituation (RANCH) model was developed [@cao2023habituation; @raz2023modeling]. RANCH describes an agent’s looking behavior as rational exploration based on a sequence of noisy perceptual samples. The model construes the looking time paradigm as a series of binary decisions: to keep sampling from the current stimulus, or to move on to the next stimulus. The model makes sampling decisions based on the Expected Information Gain (EIG) of the perceptual samples, choosing to keep looking or look away based on which one would in expectation yield the most information; it therefore can be seen as a rational analysis of looking behavior [@anderson1991human; @lieder2020resource; @oaksford1994rational]. 

RANCH also incorporates recent progress in convolutional neural networks, which have offered insights into how the visual system encodes objects [@doshi2023cortical; @hebart2020revealing; @yamins2014performance]. The activations of these brain-inspired neural networks form embedding spaces, each of which can be seen as a quantitative hypothesis about how humans represent visual stimuli [@schrimpf2020integrative]. For example, @lee2022rapid projected the final layer of a trained ResNet50 into a "perceptually-aligned" space, by making its representations match dissimilarity matrices derived from human adult reaction times in a 2-AFC match-to-sample task. Passing new stimuli through this perceptual alignment yields a plausible representation of how humans embed different visual stimuli in a low-dimensional space. Using this perceptually-aligned embedding space as a model of perceptual encoding allows RANCH to learn from raw, previously unseen images.

Previously, @cao2023habituation and @raz2023modeling have shown that RANCH can successfully model habituation and dishabituation in adults and infants. Here, we test RANCH’s ability to predict responses in new data, particularly a key phenomenon in qualitative accounts of dishabituation. To conduct these tests, we first fit RANCH’s parameters to a training data set from the habituation-dishabituation experiment in which participants saw sequences of monsters which were either familiar or novel [dataset reported in @cao2023habituation, Fig 1A]. Then, we use the best-fitting parameters to generate predictions for a new experiment designed to measure subtle differences in dishabituation magnitude based on stimulus similarity (Fig 1C). In this experiment, we systematically varied the similarity between habituation and dishabituation stimuli such that dishabituation stimuli differed in their pose angle, their number, their identity, or their animacy. This experiment tests a prediction from @hunter1988multifactor model of habituation and dishabituation: that observers’ dishabituation magnitude should be related to the similarity between the habituated stimulus and the novel stimulus. The more dissimilar two stimuli are, the more one should dishabituate to the novel stimulus.

To preview our results, we show that RANCH can predict looking time responses in new data by transferring model parameters fit from previous data, with marginal differences in performance compared to completely refitting to the new data. RANCH also captures the particular ordering of the dishabituation magnitude as a function of stimulus dissimilarity, thereby predicting a novel qualitative phenomenon (graded dishabituation) without ever being trained on it. Finally, we show that RANCH is relatively robust across parameter settings, but the assumptions about its perceptual representation, learning process, and the decision process are all critical to its performance.
